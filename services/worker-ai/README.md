# Worker AI - Servicio de Inferencia y Tracking

Servidor TCP que recibe frames del edge-agent, ejecuta YOLO11 para detectar objetos, aplica tracking BoT-SORT, y persiste los resultados en JSON por sesiÃ³n.

## ğŸ—ï¸ Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    TCP+Protobuf    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Edge Agent  â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  Worker AI   â”‚
â”‚  (Node.js)   â”‚  Length-prefixed   â”‚  (Python)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                           â”‚
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚                  â”‚                  â”‚
                   Transport          Pipeline           Server
                   â€¢ Framing         â€¢ Decoder          â€¢ Conexiones
                   â€¢ Codec           â€¢ Inference        â€¢ Heartbeats
                                     â€¢ Tracking         â€¢ Model Loader
                                     â€¢ Sessions
```

**Capas modulares:**
- **Transport**: Framing TCP y codec Protobuf
- **Pipeline**: decode â†’ inferencia â†’ tracking â†’ persistencia
- **Server**: GestiÃ³n de conexiones y coordinaciÃ³n
- **Config**: ConfiguraciÃ³n runtime centralizada

Ver [docs/ARCHITECTURE.md](docs/ARCHITECTURE.md) para detalles completos.

## ğŸš€ Inicio RÃ¡pido

**Lee esto primero**: [`QUICKSTART.md`](QUICKSTART.md) - GuÃ­a rÃ¡pida completa

### Prerequisitos

- Python 3.10+
- Mamba/Conda
- Modelo YOLO11 en formato ONNX

### InstalaciÃ³n

```bash
# Con Conda/Mamba
mamba env create -f environment.yml
mamba activate worker-ai

# Verificar que el modelo estÃ¡ disponible
ls -lh data/models/yolo11n.onnx

# Ejecutar
python worker.py

# O usar el script de conveniencia
./run.sh
```

### VerificaciÃ³n RÃ¡pida

```bash
# Test del modelo YOLO
python test_detection.py

# Inspeccionar modelo
python inspect_model.py
```

El worker escucharÃ¡ en `0.0.0.0:7001` por defecto.

### ConfiguraciÃ³n

Editar `config.toml` o crear `config.local.toml`:

```toml
[server]
bind_host = "0.0.0.0"
bind_port = 7001

[model]
conf_threshold = 0.5
nms_iou = 0.6
classes = ["person", "car"]  # Filtro opcional

[tracker]
enabled = true
config_path = "botsort.yaml"

[sessions]
output_dir = "./data/tracks"
default_fps = 10.0
segment_duration_s = 10.0

[visualization]
enabled = true
```

## ğŸ“¦ Estructura del Proyecto

```
worker-ai/
â”œâ”€â”€ worker.py              # Punto de entrada
â”œâ”€â”€ ai_pb2.py             # Protobuf generado
â”œâ”€â”€ botsort.yaml          # Config del tracker
â”œâ”€â”€ config.toml           # ConfiguraciÃ³n principal
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py           # Bootstrap principal
â”‚   â”œâ”€â”€ transport/        # Framing + Codec Protobuf
â”‚   â”œâ”€â”€ pipeline/         # Procesamiento de frames
â”‚   â”œâ”€â”€ server/           # Servidor TCP
â”‚   â”œâ”€â”€ config/           # ConfiguraciÃ³n runtime
â”‚   â”œâ”€â”€ core/             # Logger
â”‚   â”œâ”€â”€ inference/        # YOLO11 ONNX
â”‚   â”œâ”€â”€ tracking/         # BoT-SORT
â”‚   â”œâ”€â”€ session/          # Persistencia JSON
â”‚   â””â”€â”€ visualization/    # OpenCV viewer
â”œâ”€â”€ docs/                 # DocumentaciÃ³n completa
â””â”€â”€ data/tracks/          # Salida de sesiones
```

## ğŸ“ Funcionalidades

### Tracking de Objetos (BoT-SORT)

Cada detecciÃ³n recibe un `track_id` Ãºnico que persiste entre frames. Configurable en `botsort.yaml`:

```yaml
match_thresh: 0.3    # Umbral IoU para matching
max_age: 30          # Frames sin detecciÃ³n antes de eliminar
```

### GestiÃ³n de Sesiones

Cada sesiÃ³n genera:
- `tracks/seg-XXXX.jsonl`: Eventos de tracking por segmento
- `index.json`: Ãndice de segmentos
- `meta.json`: Metadatos de la sesiÃ³n

Estructura de salida:
```
data/tracks/
â””â”€â”€ session_device123_20241017_150530/
    â”œâ”€â”€ meta.json
    â”œâ”€â”€ index.json
    â””â”€â”€ tracks/
        â”œâ”€â”€ seg-0000.jsonl
        â”œâ”€â”€ seg-0001.jsonl
        â””â”€â”€ ...
```

### Protocolos Soportados

- **Init**: Carga modelo YOLO11
- **Frame**: Procesa frame (JPEG, NV12, I420)
- **End**: Finaliza sesiÃ³n
- **Heartbeat**: Keepalive durante carga de modelo

## ğŸ³ Docker

```bash
# Build
docker build -t worker-ai .

# Run
docker run -p 7001:7001 -v $(pwd)/data:/data worker-ai
```

## ğŸ“š DocumentaciÃ³n

### GuÃ­as de Usuario
- **[QUICKSTART.md](QUICKSTART.md)** - â­ Inicio rÃ¡pido (lee esto primero)
- **[EXPORTAR_MODELOS.md](EXPORTAR_MODELOS.md)** - Exportar modelos YOLO a ONNX
- **[REORGANIZATION_NOTES.md](REORGANIZATION_NOTES.md)** - Cambios y mejoras aplicadas
- **[FIX_NMS_INTEGRADO.md](FIX_NMS_INTEGRADO.md)** - ExplicaciÃ³n del fix de NMS

### DocumentaciÃ³n TÃ©cnica
- [ARCHITECTURE.md](docs/ARCHITECTURE.md) - Arquitectura detallada
- [TESTING_GUIDE.md](docs/TESTING_GUIDE.md) - GuÃ­a de testing
- [REFACTORING_SUMMARY.md](docs/REFACTORING_SUMMARY.md) - Historial de refactoring
- [examples.md](docs/examples.md) - Ejemplos de uso

## ğŸ› ï¸ Scripts Ãštiles

```bash
# Exportar modelo YOLO a ONNX
python scripts/export_yolo_to_onnx.py --weights yolo11n.pt --nms

# Test de inferencia
python test_detection.py

# Inspeccionar modelo ONNX
python inspect_model.py

# Anotar frames desde JSON
python scripts/annotate_from_json.py
```

Ver [scripts/README.md](scripts/README.md) para mÃ¡s detalles.

## ğŸ”§ Desarrollo

Ver [docs/TESTING_GUIDE.md](docs/TESTING_GUIDE.md) para:
- Testing unitario
- Testing de integraciÃ³n
- Debugging
- Profiling

### CaracterÃ­sticas Destacadas

âœ… **DetecciÃ³n automÃ¡tica de formato ONNX** (con/sin NMS integrado)  
âœ… **Soporte para 80 clases COCO**  
âœ… **Tracking BoT-SORT** con IDs persistentes  
âœ… **Persistencia en JSON** por sesiÃ³n  
âœ… **VisualizaciÃ³n en tiempo real** con OpenCV  
âœ… **ConfiguraciÃ³n flexible** vÃ­a TOML

## ğŸ“„ Licencia

Ver LICENSE en el repositorio principal.
