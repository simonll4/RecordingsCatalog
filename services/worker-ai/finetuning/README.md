# Fine-tuning YOLO11-S - Pipeline Modular

La adaptaciÃ³n a tu cÃ¡mara se centra en detectar: **person**, **bottle**, **cup**, **backpack** y **shoes**.  
El pipeline ahora estÃ¡ dividido en scripts numerados para mantener cada paso pequeÃ±o y claro.

## ğŸ“‚ Estructura (clave)

```
finetuning/
â”œâ”€â”€ mini_yolo_pipeline.py         # Wrapper (compatibilidad) â†’ delega en scripts/*
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ 01_extract_frames.py      # Paso 1 - frames
â”‚   â”œâ”€â”€ 02_labelstudio_to_yolo.py # Paso 2 - conversiÃ³n de anotaciones
â”‚   â”œâ”€â”€ 03_split_dataset.py       # Paso 3 - split train/val
â”‚   â”œâ”€â”€ 04_train_yolo.py          # Paso 4 - entrenamiento
â”‚   â”œâ”€â”€ 05_export_onnx.py         # Paso 5 - export ONNX
â”‚   â”œâ”€â”€ common.py                 # Utilidades compartidas
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ recordings/                   # Tus videos .mp4 (origen)
â”œâ”€â”€ frames/                       # Frames extraÃ­dos
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ images/{train,val}
â”‚   â””â”€â”€ labels/{train,val}
â”œâ”€â”€ runs/                         # Resultados de entrenamiento
â””â”€â”€ models/                       # Modelos ONNX exportados
```

> `mini_yolo_pipeline.py` continÃºa existiendo, pero ahora sÃ³lo reenvÃ­a al script numerado correspondiente.  
> RecomendaciÃ³n: ejecutar directamente cada `scripts/0X_*.py` para tener el control paso a paso.

## ğŸš€ Requisitos

```bash
pip install -r requirements.txt   # incluye ultralytics
sudo apt install ffmpeg           # si aÃºn no lo tienes
```

## ğŸ§­ Paso a paso (scripts numerados)

### 1ï¸âƒ£ Extraer frames (adapta iluminaciÃ³n y Ã¡ngulos de tu cÃ¡mara)

```bash
python scripts/01_extract_frames.py \
  --src recordings \
  --out frames \
  --fps 1.5 \
  --scale 1280
```

Resultado: subcarpetas en `frames/` con JPG listos para etiquetar.

### 2ï¸âƒ£ Convertir anotaciones de Label Studio â†’ YOLO

```bash
python scripts/02_labelstudio_to_yolo.py \
  --ls-json export.json \
  --images frames
  # --classes usa por defecto: person,bottle,cup,backpack,shoes
```

Esto genera:
- `dataset/_pairs_tmp/pairs.txt`
- `dataset/classes.txt` (con tus clases objetivo)

### 3ï¸âƒ£ Dividir dataset train/val

```bash
python scripts/03_split_dataset.py --ratio 0.8 --seed 42
```

Resultado: imÃ¡genes y labels en `dataset/images|labels/train|val/`.

### 4ï¸âƒ£ Entrenar YOLO11-S adaptado a la cÃ¡mara

```bash
python scripts/04_train_yolo.py \
  --model yolo11s.pt \
  --epochs 25 \
  --imgsz 640 \
  --name camera-adapted \
  --lr0 0.001 \
  --gpu           # opcional
```

Resultado: checkpoint en `runs/camera-adapted/weights/best.pt`.

### 5ï¸âƒ£ Exportar a ONNX para worker-ai

```bash
python scripts/05_export_onnx.py \
  --name camera-adapted \
  --imgsz 640 \
  --opset 13 \
  --out yolo11s_camera.onnx
```

Resultado: `models/yolo11s_camera.onnx`.

## ğŸ§© Compatibilidad con el wrapper

Si ya tenÃ­as automatizaciones basadas en el script monolÃ­tico:

```bash
python mini_yolo_pipeline.py extract-frames
python mini_yolo_pipeline.py labelstudio-to-yolo --ls-json export.json
python mini_yolo_pipeline.py split
python mini_yolo_pipeline.py train --gpu
python mini_yolo_pipeline.py export-onnx
```

Cada subcomando llama internamente al script numerado correspondiente, por lo que los argumentos siguen siendo vÃ¡lidos.

## âš™ï¸ Opciones Ãºtiles

- `01_extract_frames.py --fps 2.0` â†’ mÃ¡s densidad de frames.
- `02_labelstudio_to_yolo.py --classes "person,bottle,cup,backpack,shoes"` â†’ explÃ­cito si ajustas el orden.
- `03_split_dataset.py --ratio 0.9` â†’ mÃ¡s datos para entrenamiento.
- `04_train_yolo.py --epochs 35 --lr0 5e-4` â†’ entrenamiento mÃ¡s extenso y estable.
- `05_export_onnx.py --out camera_v2.onnx` â†’ variantes para versiones.

## ğŸ“Š ValidaciÃ³n y revisiÃ³n

- MÃ©tricas: `cat runs/camera-adapted/results.csv`
- GrÃ¡ficos: `ls runs/camera-adapted/*.png`
- ValidaciÃ³n CLI: `yolo val model=runs/camera-adapted/weights/best.pt data=dataset/data.yaml`
- Predicciones de prueba: `yolo predict model=runs/camera-adapted/weights/best.pt source=dataset/images/val save=True`

## ğŸ› Troubleshooting rÃ¡pido

- **No mp4 encontrados** â†’ verifica `recordings/`.
- **Falta ultralytics** â†’ `pip install ultralytics`.
- **Clase desconocida** â†’ confirma el orden en `--classes`.
- **Sin mejora** â†’ mÃ¡s datos de las condiciones reales (iluminaciÃ³n/dÃ­a/noche) y mÃ¡s Ã©pocas.
- **Falsos positivos** â†’ subÃ­ el `conf_threshold` o agrega ejemplos negativos.

## ğŸ” Reentrenos incrementales

1. Captura nuevos videos (distintas horas/condiciones).
2. `python scripts/01_extract_frames.py` sobre los videos nuevos.
3. Anota Ãºnicamente los frames nuevos en Label Studio.
4. Ejecuta scripts 02 â†’ 05 (puedes reusar `runs/camera-adapted/weights/best.pt` como `--model` para seguir fine-tune).

## ğŸ”Œ IntegraciÃ³n con worker-ai

```bash
cp models/yolo11s_camera.onnx ../data/models/
# Actualiza configuraciÃ³n del worker:
# model_path = "data/models/yolo11s_camera.onnx"
```

## ğŸ“š MÃ¡s recursos

- `COMMANDS.md` â†’ ejemplos concretos de cada paso.
- `quickstart.sh` â†’ guÃ­a interactiva paso a paso.
- `RESUMEN.md` â†’ visiÃ³n ejecutiva del flujo.

---

Â¿Dudas puntuales? EjecutÃ¡ cualquier script con `--help` para ver argumentos disponibles.
